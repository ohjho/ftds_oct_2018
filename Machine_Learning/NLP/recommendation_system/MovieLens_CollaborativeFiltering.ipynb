{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Lens Collaborative Filtering Movie-Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting Data\n",
    "\n",
    "### Data Source\n",
    "[Movie Lens 100K](https://grouplens.org/datasets/movielens/100k/): [description](http://files.grouplens.org/datasets/movielens/ml-100k-README.txt)\n",
    "\n",
    "### Data Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'data/ml-100k/u.data'\n",
    "data = pd.read_csv( fname, sep= '\\t', \n",
    "                   header = 0,\n",
    "                   names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for Missing and Dup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "sns.heatmap(data.isnull(), yticklabels = False, cbar = False, cmap = 'viridis')\n",
    "plt.ylabel('missing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the combo of columns that should be unique here:\n",
    "l_dup_check = ['user_id',\n",
    "               'item_id',\n",
    "               'rating'\n",
    "              ]\n",
    "\n",
    "data_dup = data[\n",
    "            data.duplicated( \n",
    "                subset = l_dup_check, \n",
    "                keep = False)\n",
    "            ]\n",
    "print( f' Found { len ( data_dup )} duplicated records.')\n",
    "\n",
    "if len(data_dup)> 0:\n",
    "    data_dup.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_users = data.user_id.unique()\n",
    "u_movies = data.item_id.unique()\n",
    "\n",
    "print(f'There are {len(u_users)} users.')\n",
    "print(f'There are {len(u_movies)} movies.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping and Summarizing\n",
    "* some [references here](https://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/)\n",
    "* get **User Rating Count Distribution**\n",
    "* get **Movie Rating Count Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_user = data.groupby(['user_id']).agg({\n",
    "        'item_id': {'movie_count':'count'},\n",
    "        'rating': {'avg_rating': 'mean'}\n",
    "    })\n",
    "agg_movie = data.groupby(['item_id']).agg({\n",
    "        'user_id': {'user_count':'count'},\n",
    "        'rating': {'avg_rating': 'mean'}\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (15, 8))\n",
    "sns.set(style = 'darkgrid', context = 'talk')\n",
    "g = sns.distplot( \n",
    "            agg_user[('item_id','movie_count')],\n",
    "            kde = False, bins = 50\n",
    "        )\n",
    "g.set_title(\"User's Review Count Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (15, 8))\n",
    "sns.set(style = 'darkgrid', context = 'talk')\n",
    "g = sns.distplot( \n",
    "            agg_movie[('user_id','user_count')],\n",
    "            kde = False, bins = 100\n",
    "        )\n",
    "g.set_title(\"Movie's Reviews Count Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (15, 8))\n",
    "sns.set(style = 'darkgrid', context = 'talk')\n",
    "g = sns.distplot( \n",
    "            agg_movie[('rating','avg_rating')],\n",
    "            kde = False, bins = 50\n",
    "        )\n",
    "g.set_title(\"Movie's Rating Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seems like we should cut out movies with less than 50 reviews\n",
    "note that from the dataset, all users have at least 20 views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_count = 10\n",
    "plt.figure( figsize = (15, 8))\n",
    "sns.set(style = 'darkgrid', context = 'talk')\n",
    "g = sns.distplot( \n",
    "            agg_movie[agg_movie['user_id', 'user_count'] > n_count][('user_id','user_count')],\n",
    "            kde = False, bins = 100\n",
    "        )\n",
    "g.set_title(f\"Movie's Reviews Count Distribution with cutoff at {n_count} reviews\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transpose Data into Matrix\n",
    "\n",
    "on how to index user_id from a multiindex column, check [here](https://jakevdp.github.io/PythonDataScienceHandbook/03.05-hierarchical-indexing.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_count = 50\n",
    "filtered_item_id = agg_movie[agg_movie['user_id', 'user_count'] > n_count].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['keep_item'] = data.item_id.apply( lambda x: x in list(filtered_item_id))\n",
    "raw = data[data.keep_item == True].loc[:,['user_id','item_id','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_matrix = pd.pivot_table( raw,\n",
    "                          values = 'rating',\n",
    "                          index = 'user_id',\n",
    "                            columns= ['item_id']\n",
    "                          )\n",
    "print(f'Filtered Dataset is of the shape (# of User, # of Movies): {ui_matrix.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finding Distance between Users\n",
    "\n",
    "#### Let's get two random users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = ui_matrix.sample(2, random_state = 420).index.values\n",
    "user1, user2 = tuple(random)\n",
    "print(f'User1 id: {user1} and User2 id:{user2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use hamming distance\n",
    "* [reference from scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.hamming.html#scipy.spatial.distance.hamming) and math expression is [this](https://en.wikipedia.org/wiki/Distance_correlation#Distance_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "def ham_distance( userid_1, userid_2, user_item_matrix):\n",
    "    try:\n",
    "        u1 = user_item_matrix[ui_matrix.index == userid_1]\n",
    "        u2 = user_item_matrix[ui_matrix.index == userid_2]\n",
    "        distance = hamming( u1, u2)\n",
    "    except:\n",
    "        distance = np.NAN\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_distance(user1, user2, ui_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get Recommendations\n",
    "* find closest neighbors\n",
    "* get average movies' rating of neighbors\n",
    "* recommend top `N` movies by ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetNeighbors(ui_mat, user_id, knearest = 10):\n",
    "    df_all = pd.DataFrame(ui_mat.index)\n",
    "    df_all = df_all[df_all.user_id != user_id]\n",
    "    df_all['distance'] = df_all.user_id.apply( lambda x : ham_distance(user_id, x, ui_mat))\n",
    "    \n",
    "    # ascending = True because hamming distance represent the percentage of the array U, V\n",
    "    #   that is different; therefore, smaller hamming distance means more similar arrays\n",
    "    neighbors = df_all.sort_values(['distance'], ascending=True) \n",
    "    return neighbors[: min(knearest, len(neighbors))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetNeighbors( ui_matrix, user1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetItemSuggest(ui_mat, user_id, N = 5):\n",
    "    neighbors_id = GetNeighbors(ui_mat, user_id, 10)['user_id']\n",
    "    neighbors_data = ui_mat[ui_mat.index.isin(list(neighbors_id)) ]\n",
    "    neighbors_items_rating = neighbors_data.apply( np.nanmean )\n",
    "    \n",
    "    OldItems = ui_mat.T[user_id].dropna().index\n",
    "    NewItems = neighbors_items_rating[~ neighbors_items_rating.index.isin(list(OldItems))]\n",
    "    NewItems_sorted = NewItems.sort_values(ascending = False).index   #<- comment out .index to see the avgRating\n",
    "    \n",
    "    return list(NewItems_sorted[ : min(N, len(NewItems_sorted))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetItemSuggest( ui_matrix, user1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "#### Get Data about Items and Users to see if it make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'data/ml-100k/u.item'\n",
    "idata = pd.read_csv( fname, sep= '|', \n",
    "                   header = 0,\n",
    "                   names = [\n",
    "                       'item_id','movie_title','release_date','video_release_date',\n",
    "                       'IMDb_URL','unknown','Action','Adventure','Animation','Children',\n",
    "                       'Comedy','Crime','Documentary','Drama','Fantasy','Film-Noir','Horror',\n",
    "                       'Musical','Mystery','Romance','Sci-Fi','Thriller','War','Western'],\n",
    "                    encoding = 'iso-8859-1'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do we suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies = GetItemSuggest( ui_matrix, user2, 10)\n",
    "idata[ idata.item_id.isin(Movies)][['item_id','movie_title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What Does He currently Like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetUserMovieList(ui_mat, user_id, df_item):\n",
    "    OldItems = ui_mat.T[user_id].dropna().index\n",
    "    return df_item[ df_item.item_id.isin(OldItems)][['item_id','movie_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetUserMovieList(ui_matrix, user2, idata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Basic Info about this User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'data/ml-100k/u.user'\n",
    "udata = pd.read_csv( fname, sep= '|', \n",
    "                       header = 0,\n",
    "                       names = ['user_id','age','gender','occupation','zip_code'],\n",
    "                        encoding = 'iso-8859-1'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udata[udata.user_id == user2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
