{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Mathematical Differentiation\n",
    "\n",
    "Differentiation is the action of computing a derivative. The derivative of a function y = f(x) of a variable x is a measure of the rate at which the value y of the function changes with respect to the change of the variable x. It is called the derivative of f with respect to x. If x and y are real numbers, and if the graph of f is plotted against x, the derivative is the slope of this graph at each point.\n",
    "\n",
    "\n",
    "Rough Graphical Meaning for derivative is shown below\n",
    "\n",
    "![Slope of Tagent Line at at a specified point is viewed as the first derivative of the function](img/Tangentcalculus.png)\n",
    "\n",
    "\n",
    "\n",
    "Rigorous Definition\n",
    "\n",
    "The most common approach to turn this intuitive idea into a precise definition is to define the derivative as a limit of difference quotients of real number.\n",
    "\n",
    "We can interprete the derivative as the limit at a specified point\n",
    "\n",
    "![limit definition of derivative](img/limitderivative.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing derivative in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1: Simple derivative\n",
    "\n",
    "$f(x) = x^{2}$\n",
    "\n",
    "$f'(x) = 2x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xSquared(x):\n",
    "    return x**2\n",
    "\n",
    "def getDeriv(func, x):\n",
    "  h = 0.0001\n",
    "  return (func(x+h) - func(x)) / h\n",
    "\n",
    "\n",
    "# f'(3) = 6.0001\n",
    "\n",
    "x = 3\n",
    "derivative = getDeriv(xSquared, x)\n",
    "actual = 2*x\n",
    "\n",
    "#derivative, actual = 6.0001, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.000100000012054 6\n"
     ]
    }
   ],
   "source": [
    "print(derivative, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2: Scipy derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.00000000550085"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.misc import derivative\n",
    "def f(x):\n",
    "    return x**3 + x**2\n",
    "\n",
    "derivative(f, 3.0, dx=1e-6)  # f'(3) with h = 0.0000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivative in machine learning\n",
    "\n",
    "Machine learning uses derivatives to find optimal solutions to problems. It’s useful in optimization functions like Gradient Descent because it helps us decide whether to increase or decrease our weights in order to maximize or minimize some metrics (e.g. loss)\n",
    "\n",
    "It also helps us model nonlinear functions as linear functions (tangent lines), which have constant slopes. With a constant slope we can decide whether to move up or down the slope (increase or decrease our weights) to get closer to the target value (class label)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khan Academy Video on Derivative\n",
    "\n",
    "https://www.khanacademy.org/math/ap-calculus-ab/ab-derivative-intro/ab-derivative-intuition/v/derivative-as-a-concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient\n",
    "\n",
    "A gradient is a vector that stores the partial derivatives of multivariable functions. It helps us calculate the slope at a specific point on a curve for functions with multiple independent variables. In order to calculate this more complex slope, we need to isolate each variable to determine how it impacts the output on its own. To do this we iterate through each of the variables and calculate the derivative of the function after holding all other variables constant. Each iteration produces a partial derivative which we store in the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of gradient for multivariate function\n",
    "\n",
    "$f(x,z) = 2z^{3}x^{2}$\n",
    "\n",
    "$\\frac{\\text{d}f}{\\text{d}x}(x,z) = 4z^{3}x$\n",
    "\n",
    "$\\frac{\\text{d}f}{\\text{d}z}(x,z) = 6z^{2}x^{2}$\n",
    "\n",
    "\n",
    "The partial derivatives are then stored in the following format called as gradient\n",
    "\n",
    "![gradient](img/gradient.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Implementation on gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  1.  1.5 2. ]\n",
      "[0.5  0.5  0.75 1.  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "f = np.array([1,2,3,5], dtype=float)\n",
    "print(np.gradient(f))\n",
    "print(np.gradient(f, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directional Derivative\n",
    "\n",
    "Another important concept is directional derivatives. When calculating the partial derivatives of multivariable functions we use our old technique of analyzing the impact of infinitesimally small increases to each of our independent variables. By increasing each variable we alter the function output in the direction of the slope.\n",
    "\n",
    "But what if we want to change directions? For example, imagine we’re traveling north through mountainous terrain on a 3-dimensional plane. The gradient we calculated above tells us we’re traveling north at our current location. But what if we wanted to travel southwest? How can we determine the steepness of the hills in the southwest direction? Directional derivatives help us find the slope if we move in a direction different from the one specified by the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khan Academy Video on Directional Derivative\n",
    "\n",
    "https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/directional-derivative-introduction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient and Directional Derivative in Deep Learning\n",
    "\n",
    "Gradients are used in neural networks to adjust weights and optimize cost functions.\n",
    "\n",
    "Gradient Descent\n",
    "The relevant concept in deep learning is called gradient descent. In gradient descent, neural networks use property #1 above to determine how to adjust their weights for each variable (feature) in the model. Rather than moving in the direction of greatest increase, as specified by the gradient, neural networks move in the opposite direction to minimize a loss function, like error percent or Log Loss. After adjusting their weights, neural networks compute the gradient again and move in the direction opposite to the one specified by the gradient.\n",
    "\n",
    "Adjusting Weights\n",
    "Neural networks use the concept of directional derivatives to adjust their weights. After computing the gradient of the current weights (features), neural networks identify the direction of greatest decrease to the loss function, and then multiply the current weights by a vector (or matrix) containing the direction and magnitude that minimizes the loss function. The networks can change their weights with varying magnitudes, but the changes must be proportional to maintain the proper direction of greatest decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain Rule\n",
    "\n",
    "The chain rule is a formula for calculating the derivatives of composite functions. \n",
    "Composite functions are functions composed of functions inside other function.\n",
    "\n",
    "Composite Function and its relationship between Chain Rule is demonstrated in the following graph\n",
    "\n",
    "![Composite Function and Chain Rule](img/compositechainrule.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khan Academy Video on Chain Rule\n",
    "\n",
    "https://www.khanacademy.org/math/ap-calculus-ab/ab-derivative-rules/ab-chain-rule/v/chain-rule-introduction    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference:\n",
    "# http://wiki.fast.ai/index.php/Calculus_for_Deep_Learning\n",
    "# https://en.wikipedia.org/wiki/Derivative\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.derivative.html\n",
    "# https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.gradient.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
